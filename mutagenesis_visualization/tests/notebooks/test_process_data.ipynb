{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T20:36:42.923005Z",
     "iopub.status.busy": "2021-01-25T20:36:42.922649Z",
     "iopub.status.idle": "2021-01-25T20:36:44.684779Z",
     "shell.execute_reply": "2021-01-25T20:36:44.684176Z",
     "shell.execute_reply.started": "2021-01-25T20:36:42.922978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from code_process_data.ipynb\n",
      "importing Jupyter notebook from code_utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from pandas.testing import assert_frame_equal\n",
    "import os\n",
    "from itertools import product\n",
    "from random import randint, random\n",
    "import logging\n",
    "import tempfile\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "log: logging.Logger = logging.getLogger('test_process_data')\n",
    "\n",
    "try:\n",
    "    from mutagenesis_visualization.main.scripts.code_process_data import (\n",
    "        count_reads, calculate_enrichment, assemble_sublibraries,\n",
    "        _initialize_ordereddict, msa_enrichment\n",
    "    )\n",
    "except ModuleNotFoundError:\n",
    "    import import_notebook\n",
    "    import os\n",
    "    directory = os.getcwd()\n",
    "    new_directory = directory.replace('tests', 'main')\n",
    "    os.chdir(new_directory)\n",
    "    from code_process_data import count_reads, calculate_enrichment, assemble_sublibraries, _initialize_ordereddict, msa_enrichment\n",
    "    os.chdir(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To run these tests run pytest from the root directory. \"Test CCT\" is the one\n",
    "that fails.\n",
    "\n",
    "Other bits and bobs:\n",
    "    In _enumerate_variants you don't use firstwtseq so you can remove that. And\n",
    "    if that goes you can also not pass dna_sequence.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def test_count_reads():\n",
    "    # Need to remove firstwtseq from _enumerate_variants\n",
    "\n",
    "    def mut_assert_df_equal(left: pd.DataFrame, right: pd.DataFrame):\n",
    "        assert_frame_equal(\n",
    "            left,\n",
    "            right,\n",
    "            check_dtype=False,\n",
    "            check_index_type=False,\n",
    "            check_column_type=False,\n",
    "            check_frame_type=False,\n",
    "            check_names=False,\n",
    "            check_like=True,\n",
    "        )\n",
    "\n",
    "    # File location\n",
    "    # Use relative file import to access the data folder\n",
    "    try:\n",
    "        location = os.path.dirname(os.path.realpath(__file__))\n",
    "        my_file = os.path.join(location, '../../data/for_tests', \"short.fastq\")\n",
    "    except NameError:\n",
    "        my_file = os.path.join('../../data/for_tests', \"short.fastq\")\n",
    "\n",
    "    # Create dataframe\n",
    "    codon_list = [\n",
    "        'AAA', 'AAC', 'AAG', 'AAT', 'ACA', 'ACC', 'ACG', 'ACT', 'AGA', 'AGC',\n",
    "        'AGG', 'AGT', 'ATA', 'ATC', 'ATG', 'ATT', 'CAA', 'CAC', 'CAG', 'CAT',\n",
    "        'CCA', 'CCC', 'CCG', 'CCT', 'CGA', 'CGC', 'CGG', 'CGT', 'CTA', 'CTC',\n",
    "        'CTG', 'CTT', 'GAA', 'GAC', 'GAG', 'GAT', 'GCA', 'GCC', 'GCG', 'GCT',\n",
    "        'GGA', 'GGC', 'GGG', 'GGT', 'GTA', 'GTC', 'GTG', 'GTT', 'TAA', 'TAC',\n",
    "        'TAG', 'TAT', 'TCA', 'TCC', 'TCG', 'TCT', 'TGA', 'TGC', 'TGG', 'TGT',\n",
    "        'TTA', 'TTC', 'TTG', 'TTT'\n",
    "    ]\n",
    "    index = pd.Index(codon_list)\n",
    "    column_counts = pd.Index([2])\n",
    "    column_wt = pd.Index([\"Position\", \"Codon\", \"Aminoacid\", \"Counts\"])\n",
    "    values_cct = values_atc = [0] * 23 + [1] + [0] * 40\n",
    "\n",
    "    # Test ATG\n",
    "    expected_atc_counts = pd.DataFrame(\n",
    "        values_atc, index=index, columns=column_counts\n",
    "    )\n",
    "    expected_atc_wt = pd.DataFrame([], columns=column_wt)\n",
    "    atg_counts, atg_wt = count_reads(\"atg\", my_file, codon_list)\n",
    "    # return atg_counts\n",
    "    mut_assert_df_equal(atg_counts, expected_atc_counts)\n",
    "    mut_assert_df_equal(atg_wt, expected_atc_wt)\n",
    "\n",
    "    # Test CCT\n",
    "    expected_cct_counts = pd.DataFrame(\n",
    "        values_cct, index=index, columns=column_counts\n",
    "    )\n",
    "    expected_cct_wt = pd.DataFrame([[2, 'CCA', 'P', 0], [2, 'CCC', 'P', 0],\n",
    "                                    [2, 'CCG', 'P', 0]],\n",
    "                                   index=[20, 21, 22],\n",
    "                                   columns=column_wt)\n",
    "    cct_counts, cct_wt = count_reads(\"cCt\", my_file, codon_list)\n",
    "    mut_assert_df_equal(cct_counts, expected_cct_counts)\n",
    "    mut_assert_df_equal(cct_wt, expected_cct_wt)\n",
    "\n",
    "    # Test CCT when not in codon list\n",
    "    index = pd.Index([\n",
    "        \"GCC\",\n",
    "        \"GCG\",\n",
    "        \"TGC\",\n",
    "        \"GAC\",\n",
    "        \"GAG\",\n",
    "        \"TTC\",\n",
    "        \"GGC\",\n",
    "        \"GGG\",\n",
    "        \"CAC\",\n",
    "        \"ATC\",\n",
    "        \"AAG\",\n",
    "        \"CTC\",\n",
    "        \"CTG\",\n",
    "        \"TTG\",\n",
    "        \"ATG\",\n",
    "        \"AAC\",\n",
    "        \"CCC\",\n",
    "        \"CCG\",\n",
    "        \"CAG\",\n",
    "        \"CGC\",\n",
    "        \"CGG\",\n",
    "        \"AGG\",\n",
    "        \"TCC\",\n",
    "        \"TCG\",\n",
    "        \"AGC\",\n",
    "        \"ACC\",\n",
    "        \"ACG\",\n",
    "        \"GTC\",\n",
    "        \"GTG\",\n",
    "        \"TGG\",\n",
    "        \"TAC\",\n",
    "        \"TAG\",\n",
    "    ])\n",
    "    values_cct = [0] * 32\n",
    "    expected_cct_counts = pd.DataFrame(\n",
    "        values_cct, index=index, columns=column_counts\n",
    "    )\n",
    "    expected_cct_wt = pd.DataFrame([[2, 'CCC', 'P', 0], [2, 'CCG', 'P', 0]],\n",
    "                                   index=[16, 17],\n",
    "                                   columns=column_wt)\n",
    "    cct_counts, cct_wt = count_reads(\"cCt\", my_file, 'NNS')\n",
    "    mut_assert_df_equal(cct_counts, expected_cct_counts)\n",
    "    mut_assert_df_equal(cct_wt, expected_cct_wt)\n",
    "\n",
    "    # Now check with NNK\n",
    "    # Create a temporary directory using the context manager\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "        cct_counts, cct_wt, info = count_reads(\n",
    "            dna_sequence=\"cCt\",\n",
    "            input_file=my_file,\n",
    "            codon_list='NNK',\n",
    "            output_file=tmpdirname + '/counts.xlsx',\n",
    "            full=True,\n",
    "        )\n",
    "\n",
    "    values_cct = [0] * 17 + [1] + [0] * 14\n",
    "    index = [\n",
    "        'GCG', 'GCT', 'TGT', 'GAT', 'GAG', 'TTT', 'GGG', 'GGT', 'CAT', 'ATT',\n",
    "        'AAG', 'CTG', 'CTT', 'TTG', 'ATG', 'AAT', 'CCG', 'CCT', 'CAG', 'AGG',\n",
    "        'CGG', 'CGT', 'AGT', 'TCG', 'TCT', 'ACG', 'ACT', 'GTG', 'GTT', 'TGG',\n",
    "        'TAT', 'TAG'\n",
    "    ]\n",
    "    expected_cct_counts = pd.DataFrame(\n",
    "        values_cct, index=index, columns=column_counts\n",
    "    )\n",
    "    expected_cct_wt = pd.DataFrame([[2, 'CCG', 'P', 0]],\n",
    "                                   index=[16],\n",
    "                                   columns=column_wt)\n",
    "    mut_assert_df_equal(cct_counts, expected_cct_counts)\n",
    "    mut_assert_df_equal(cct_wt, expected_cct_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_calculate_enrichment():\n",
    "    # Read counts from file (could be txt, csv, xlsx, etc...)\n",
    "    prefix = \"mutagenesis_visualization/\"\n",
    "    # prefix = \"../../\"\n",
    "    df_counts_pre = pd.read_excel(\n",
    "        prefix + 'data/hrasGAPGEF_counts.xlsx',\n",
    "        'R1_before',\n",
    "        skiprows=1,\n",
    "        index_col='Codons',\n",
    "        usecols='E:FN',\n",
    "        nrows=32\n",
    "    )\n",
    "\n",
    "    df_counts_sel = pd.read_excel(\n",
    "        prefix + 'data/hrasGAPGEF_counts.xlsx',\n",
    "        'R1_after',\n",
    "        skiprows=1,\n",
    "        index_col='Codons',\n",
    "        usecols='E:FN',\n",
    "        nrows=32\n",
    "    )\n",
    "\n",
    "    # Ras parameters to create an object\n",
    "\n",
    "    # Order of amino acids (from count_reads)\n",
    "    aminoacids_NNS = list('AACDEFGGHIKLLLMNPPQRRRSSSTTVVWY*')\n",
    "\n",
    "    # TODO: do 0 and then a random number from 100 - 1000\n",
    "    stopcodon = [\"True\", \"False\"]\n",
    "    min_counts = [0, randint(100, 1000)]\n",
    "    mpop = [0.01, (random() + 0.01) * 10]  # mpop 0 causes an error\n",
    "    common_args = [stopcodon, min_counts, mpop]\n",
    "\n",
    "    # \"wt\" requires pre_wt\n",
    "    zeroing_compatible = [\"population\"]\n",
    "    # \"zscore\" zeroing broken at \"elif zeroing == \"zscore\"\"\n",
    "    zeroing_other = [\"kernel\", \"counts\"]\n",
    "    how = [\"median\", \"mean\", \"mode\"]\n",
    "    std_scale = [0.1, randint(0, 100)]\n",
    "\n",
    "    log.info(f\"{min_counts=}\")\n",
    "    log.info(f\"{mpop=}\")\n",
    "    log.info(f\"{std_scale=}\")\n",
    "\n",
    "    args_how_scale = product(\n",
    "        zeroing_compatible, how, [True], std_scale, *common_args\n",
    "    )\n",
    "    args_how_no_scale = product(zeroing_compatible, how, [False], *common_args)\n",
    "    args_no_how_scale = product(zeroing_other, [True], std_scale, *common_args)\n",
    "    args_no_how_no_scale = product(zeroing_other, [False], *common_args)\n",
    "\n",
    "    for args in args_how_scale:\n",
    "        #print(args)\n",
    "        zeroing, how, norm_std, std_scale, *common_args = args\n",
    "        stopcodon, min_counts, mpop = common_args\n",
    "        frequencies = calculate_enrichment(\n",
    "            df_counts_pre.iloc[:, :54],\n",
    "            df_counts_sel.iloc[:, :54],\n",
    "            zeroing=zeroing,\n",
    "            how=how,\n",
    "            norm_std=norm_std,\n",
    "            std_scale=std_scale,\n",
    "            aminoacids=aminoacids_NNS,\n",
    "            stopcodon=stopcodon,\n",
    "            min_counts=min_counts,\n",
    "            min_countswt=100,\n",
    "            mpop=mpop,\n",
    "            mwt=2,\n",
    "            infinite=3\n",
    "        )\n",
    "    for args in args_no_how_scale:\n",
    "        #print(args)\n",
    "        zeroing, how, norm_std, *common_args = args\n",
    "        stopcodon, min_counts, mpop = common_args\n",
    "        frequencies = calculate_enrichment(\n",
    "            df_counts_pre.iloc[:, :54],\n",
    "            df_counts_sel.iloc[:, :54],\n",
    "            zeroing=zeroing,\n",
    "            how=how,\n",
    "            norm_std=norm_std,\n",
    "            aminoacids=aminoacids_NNS,\n",
    "            stopcodon=stopcodon,\n",
    "            min_counts=min_counts,\n",
    "            min_countswt=100,\n",
    "            mpop=mpop,\n",
    "            mwt=2,\n",
    "            infinite=3\n",
    "        )\n",
    "    for args in args_how_no_scale:\n",
    "        #print(args)\n",
    "        zeroing, norm_std, std_scale, *common_args = args\n",
    "        stopcodon, min_counts, mpop = common_args\n",
    "        frequencies = calculate_enrichment(\n",
    "            df_counts_pre.iloc[:, :54],\n",
    "            df_counts_sel.iloc[:, :54],\n",
    "            zeroing=zeroing,\n",
    "            norm_std=norm_std,\n",
    "            std_scale=std_scale,\n",
    "            aminoacids=aminoacids_NNS,\n",
    "            stopcodon=stopcodon,\n",
    "            min_counts=min_counts,\n",
    "            min_countswt=100,\n",
    "            mpop=mpop,\n",
    "            mwt=2,\n",
    "            infinite=3\n",
    "        )\n",
    "    for args in args_how_scale:\n",
    "        #print(args)\n",
    "        zeroing, norm_std, *common_args = args\n",
    "        stopcodon, min_counts, mpop = common_args\n",
    "        frequencies = calculate_enrichment(\n",
    "            df_counts_pre.iloc[:, :54],\n",
    "            df_counts_sel.iloc[:, :54],\n",
    "            zeroing=zeroing,\n",
    "            norm_std=norm_std,\n",
    "            aminoacids=aminoacids_NNS,\n",
    "            stopcodon=stopcodon,\n",
    "            min_counts=min_counts,\n",
    "            min_countswt=100,\n",
    "            mpop=mpop,\n",
    "            mwt=2,\n",
    "            infinite=3\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_assemble_sublibraries():\n",
    "    # There aren't actually very many arguments to test here.  Once you remove\n",
    "    # - all arguments that are just forwarded to calculate_enrichment\n",
    "    # - the filename and excel sheet arguments\n",
    "    # - treat the columns_wt arguments as either there or not\n",
    "    # You're left with testing columns, nrows_pop, and columns_wt as a bool\n",
    "\n",
    "    alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "    pairs = [a + b for a, b in product(alphabet, alphabet)]\n",
    "    all_columns = list(alphabet[5:]) + pairs[:144]\n",
    "    col_lists = [partition_list(all_columns, i) for i in range(2, 6)]\n",
    "\n",
    "    nrows_list = [randint(1, 31) for _ in range(3)] + [32]\n",
    "    aminos = list(reversed(\"AACDEFGGHIKLLLMNPPQRRRSSSTTVVWY*\"))\n",
    "    amino_list = [list(reversed(aminos[:rows])) for rows in nrows_list]\n",
    "\n",
    "    col_wt_list = [['A', 'B', 'C']]\n",
    "\n",
    "    args = product(col_lists, col_wt_list, zip(nrows_list, amino_list))\n",
    "\n",
    "    filename = \"mutagenesis_visualization/data/hrasGAPGEF_counts.xlsx\"\n",
    "    # filename = \"../../data/hrasGAPGEF_counts.xlsx\"\n",
    "    sheet_pre = \"R1_before\"\n",
    "    sheet_post = \"R1_after\"\n",
    "    columns_wt = ['A', 'B', 'C']\n",
    "    nrows_pop = 32\n",
    "    nrows_wt = [50, 37, 57]\n",
    "\n",
    "    for columns, columns_wt, nrows_aminos in args:\n",
    "        nrows_pop, aminos = nrows_aminos\n",
    "        #print(f\"{columns=}\\t{columns_wt=}\\t{nrows_pop=}\")\n",
    "        df = assemble_sublibraries(\n",
    "            excel_path=filename,\n",
    "            sheet_pre=sheet_pre,\n",
    "            sheet_post=sheet_post,\n",
    "            columns=columns,\n",
    "            nrows_pop=nrows_pop,\n",
    "            nrows_wt=nrows_wt,\n",
    "            columns_wt=columns_wt,\n",
    "            aminoacids=aminos,\n",
    "            output_file=None\n",
    "        )\n",
    "\n",
    "\n",
    "def partition_list(array, num_partitions):\n",
    "    \"\"\"Partition array randomly where each partition has at least one item.\"\"\"\n",
    "    if num_partitions < 2:\n",
    "        return [f\"{array[0]}:{array[-1]}\"]\n",
    "    partition_idxs = []\n",
    "    while len(partition_idxs) < num_partitions - 1:\n",
    "        num = randint(0, len(array) - 1)\n",
    "        if num not in partition_idxs:\n",
    "            tmp_parts = partition_idxs.copy()\n",
    "            tmp_parts.append(num)\n",
    "            tmp_parts.sort()\n",
    "            idx = tmp_parts.index(num)\n",
    "            if idx != 0:\n",
    "                if tmp_parts[idx] - tmp_parts[idx - 1] < 1:\n",
    "                    continue\n",
    "            if idx != len(tmp_parts) - 1:\n",
    "                if tmp_parts[idx + 1] - tmp_parts[idx] < 1:\n",
    "                    continue\n",
    "            partition_idxs.append(num)\n",
    "    partition_idxs.sort()\n",
    "    parts = [f\"{array[0]}:{array[partition_idxs[0] - 1]}\"]\n",
    "    for start, end in zip(partition_idxs, partition_idxs[1:]):\n",
    "        parts.append(f\"{array[start]}:{array[end - 1]}\")\n",
    "    parts.append(f\"{array[partition_idxs[-1]]}:{array[-1]}\")\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_initialize_ordereddict():\n",
    "    variants = _initialize_ordereddict(['ACC', 'CCT'])\n",
    "    assert (isinstance(variants, OrderedDict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shannon tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T20:36:47.000539Z",
     "iopub.status.busy": "2021-01-25T20:36:47.000259Z",
     "iopub.status.idle": "2021-01-25T20:36:47.009710Z",
     "shell.execute_reply": "2021-01-25T20:36:47.008765Z",
     "shell.execute_reply.started": "2021-01-25T20:36:47.000495Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_msa_enrichment():\n",
    "\n",
    "    # File location\n",
    "    # Use relative file import to access the data folder\n",
    "    try:\n",
    "        location = os.path.dirname(os.path.realpath(__file__))\n",
    "        my_file = os.path.join(location, '../../data/for_tests', \"msa.fasta\")\n",
    "    except NameError:\n",
    "        my_file = os.path.join('../../data/for_tests', \"msa.fasta\")\n",
    "    \n",
    "    # Create fake data\n",
    "    class test_obj:\n",
    "        dataframe = pd.DataFrame(\n",
    "            index=[\n",
    "                'Q', 'V', 'W', 'L', 'I', 'M', 'K', 'C', 'N', 'S', 'Y', 'D', 'F',\n",
    "                'G', 'R', 'E', 'H', 'P', 'T', 'A'\n",
    "            ]\n",
    "        )\n",
    "        dataframe['Position'] = np.arange(0,20)\n",
    "        dataframe['Score'] = [0]*20\n",
    "        dataframe['Aminoacid'] = list('ACDEFGHIKLMNPQRSTVWY')\n",
    "    # Create test object\n",
    "    test = test_obj()\n",
    "    # Get df\n",
    "    df, df_freq = msa_enrichment(test, my_file, 0)\n",
    "    assert df['Shannon'].sum() == 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
